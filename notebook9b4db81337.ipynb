{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1355361,"sourceType":"datasetVersion","datasetId":789090}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:09:19.518351Z","iopub.execute_input":"2024-11-17T08:09:19.518707Z","iopub.status.idle":"2024-11-17T08:09:19.896035Z","shell.execute_reply.started":"2024-11-17T08:09:19.518656Z","shell.execute_reply":"2024-11-17T08:09:19.895098Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hindi-english-parallel-corpus/hindi_english_parallel.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install -q bpemb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:09:19.897194Z","iopub.execute_input":"2024-11-17T08:09:19.897607Z","iopub.status.idle":"2024-11-17T08:09:31.512683Z","shell.execute_reply.started":"2024-11-17T08:09:19.897573Z","shell.execute_reply":"2024-11-17T08:09:31.511406Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install -q torchsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:09:47.358640Z","iopub.execute_input":"2024-11-17T08:09:47.359045Z","iopub.status.idle":"2024-11-17T08:09:58.859550Z","shell.execute_reply.started":"2024-11-17T08:09:47.359005Z","shell.execute_reply":"2024-11-17T08:09:58.858383Z"}},"outputs":[{"name":"stdout","text":"Note: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport torch \nimport torch.nn as nn\nfrom bpemb import BPEmb\nfrom torchsummary import summary\nfrom tqdm import tqdm\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:10:15.519397Z","iopub.execute_input":"2024-11-17T08:10:15.520261Z","iopub.status.idle":"2024-11-17T08:10:18.156520Z","shell.execute_reply.started":"2024-11-17T08:10:15.520221Z","shell.execute_reply":"2024-11-17T08:10:18.155531Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/hindi-english-parallel-corpus/hindi_english_parallel.csv')\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:10:42.446327Z","iopub.execute_input":"2024-11-17T08:10:42.446910Z","iopub.status.idle":"2024-11-17T08:10:53.462213Z","shell.execute_reply.started":"2024-11-17T08:10:42.446869Z","shell.execute_reply":"2024-11-17T08:10:53.461256Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                               hindi  \\\n0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n\n                                          english  \n0  Give your application an accessibility workout  \n1               Accerciser Accessibility Explorer  \n2  The default plugin layout for the bottom panel  \n3     The default plugin layout for the top panel  \n4  A list of plugins that are disabled by default  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hindi</th>\n      <th>english</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n      <td>Give your application an accessibility workout</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n      <td>Accerciser Accessibility Explorer</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n      <td>The default plugin layout for the bottom panel</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n      <td>The default plugin layout for the top panel</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n      <td>A list of plugins that are disabled by default</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"data.dropna(inplace=True)\ndata.drop_duplicates(inplace=True)\ndata.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:11:12.950968Z","iopub.execute_input":"2024-11-17T08:11:12.951885Z","iopub.status.idle":"2024-11-17T08:11:15.771480Z","shell.execute_reply.started":"2024-11-17T08:11:12.951831Z","shell.execute_reply":"2024-11-17T08:11:15.770509Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nIndex: 1353877 entries, 0 to 1561839\nData columns (total 2 columns):\n #   Column   Non-Null Count    Dtype \n---  ------   --------------    ----- \n 0   hindi    1353877 non-null  object\n 1   english  1353877 non-null  object\ndtypes: object(2)\nmemory usage: 31.0+ MB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"data['english_len'] = data['english'].apply(lambda x:len(x.split()))\ndata['hindi_len'] = data['hindi'].apply(lambda x:len(x.split()))\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:11:41.403989Z","iopub.execute_input":"2024-11-17T08:11:41.404447Z","iopub.status.idle":"2024-11-17T08:11:46.114124Z","shell.execute_reply.started":"2024-11-17T08:11:41.404407Z","shell.execute_reply":"2024-11-17T08:11:46.113167Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                               hindi  \\\n0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n1                    एक्सेर्साइसर पहुंचनीयता अन्वेषक   \n2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n\n                                          english  english_len  hindi_len  \n0  Give your application an accessibility workout            6          8  \n1               Accerciser Accessibility Explorer            3          3  \n2  The default plugin layout for the bottom panel            8          7  \n3     The default plugin layout for the top panel            8          7  \n4  A list of plugins that are disabled by default            9         12  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hindi</th>\n      <th>english</th>\n      <th>english_len</th>\n      <th>hindi_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n      <td>Give your application an accessibility workout</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>एक्सेर्साइसर पहुंचनीयता अन्वेषक</td>\n      <td>Accerciser Accessibility Explorer</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n      <td>The default plugin layout for the bottom panel</td>\n      <td>8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n      <td>The default plugin layout for the top panel</td>\n      <td>8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n      <td>A list of plugins that are disabled by default</td>\n      <td>9</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"data = data[(data.english_len>=5) & (data.english_len<=15) & (data.hindi_len>=5) & (data.hindi_len<=15)]\ndata.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:12:01.102153Z","iopub.execute_input":"2024-11-17T08:12:01.103060Z","iopub.status.idle":"2024-11-17T08:12:01.148522Z","shell.execute_reply.started":"2024-11-17T08:12:01.103015Z","shell.execute_reply":"2024-11-17T08:12:01.147514Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                               hindi  \\\n0    अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें   \n2              निचले पटल के लिए डिफोल्ट प्लग-इन खाका   \n3               ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका   \n4  उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...   \n6  पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्स...   \n\n                                             english  english_len  hindi_len  \n0     Give your application an accessibility workout            6          8  \n2     The default plugin layout for the bottom panel            8          7  \n3        The default plugin layout for the top panel            8          7  \n4     A list of plugins that are disabled by default            9         12  \n6  The duration of the highlight box when selecti...           10         10  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hindi</th>\n      <th>english</th>\n      <th>english_len</th>\n      <th>hindi_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें</td>\n      <td>Give your application an accessibility workout</td>\n      <td>6</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>निचले पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n      <td>The default plugin layout for the bottom panel</td>\n      <td>8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका</td>\n      <td>The default plugin layout for the top panel</td>\n      <td>8</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से नि...</td>\n      <td>A list of plugins that are disabled by default</td>\n      <td>9</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्स...</td>\n      <td>The duration of the highlight box when selecti...</td>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"data = data.sample(n=25000, random_state=0)\ntrain_split, test_split = train_test_split(data, test_size=0.1, random_state=0)\ntrain_split = train_split.reset_index(0).drop(['index'], axis=1)\ntest_split = test_split.reset_index(0).drop(['index'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:12:17.162475Z","iopub.execute_input":"2024-11-17T08:12:17.163519Z","iopub.status.idle":"2024-11-17T08:12:17.201931Z","shell.execute_reply.started":"2024-11-17T08:12:17.163472Z","shell.execute_reply":"2024-11-17T08:12:17.200855Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"print(len(train_split), len(test_split))\ntrain_split.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:12:26.651672Z","iopub.execute_input":"2024-11-17T08:12:26.652558Z","iopub.status.idle":"2024-11-17T08:12:26.663273Z","shell.execute_reply.started":"2024-11-17T08:12:26.652506Z","shell.execute_reply":"2024-11-17T08:12:26.662304Z"}},"outputs":[{"name":"stdout","text":"22500 2500\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                               hindi  \\\n0    एक खूब छोटा अंश जिस में तत्वों के गुण होते है।    \n1     कोटा जानकारी समर्थित नहीं फ़ोल्डर '% s' के लिए   \n2       परन्तु यह शीघ्र ही अपर्याप्त प्रतीत हुआ...।    \n3  उसने गिरफ्तार व्यक्ति के लिए प्रतिभू की भूमिका...   \n4  अल्लाह से क्षमा की प्रार्थना करो। निस्संदेह अल...   \n\n                                             english  english_len  hindi_len  \n0  A very small component acquiring a quality of ...            9         11  \n1         No IMAP mailbox available for folder '% s'            8          9  \n2         But soon this was found rather inadequate.            7          7  \n3  He acted as ad - promisor for the arrested per...           10          9  \n4  Ask God for forgiveness: He is most forgiving ...           10         12  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>hindi</th>\n      <th>english</th>\n      <th>english_len</th>\n      <th>hindi_len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>एक खूब छोटा अंश जिस में तत्वों के गुण होते है।</td>\n      <td>A very small component acquiring a quality of ...</td>\n      <td>9</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>कोटा जानकारी समर्थित नहीं फ़ोल्डर '% s' के लिए</td>\n      <td>No IMAP mailbox available for folder '% s'</td>\n      <td>8</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>परन्तु यह शीघ्र ही अपर्याप्त प्रतीत हुआ...।</td>\n      <td>But soon this was found rather inadequate.</td>\n      <td>7</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>उसने गिरफ्तार व्यक्ति के लिए प्रतिभू की भूमिका...</td>\n      <td>He acted as ad - promisor for the arrested per...</td>\n      <td>10</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>अल्लाह से क्षमा की प्रार्थना करो। निस्संदेह अल...</td>\n      <td>Ask God for forgiveness: He is most forgiving ...</td>\n      <td>10</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"## Tokenization approaches\nTokenization is of two types:\n1)character level\n2)word level","metadata":{}},{"cell_type":"code","source":"# this is basically the module by which we're gonna perform tokenization according to the Byte-Level Byte Pair Encoding\nbpemb_en = BPEmb(lang='en')\nbpemb_hi = BPEmb(lang='hi')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:16:38.975558Z","iopub.execute_input":"2024-11-17T08:16:38.976587Z","iopub.status.idle":"2024-11-17T08:17:04.078346Z","shell.execute_reply.started":"2024-11-17T08:16:38.976544Z","shell.execute_reply":"2024-11-17T08:17:04.077471Z"}},"outputs":[{"name":"stdout","text":"downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 400869/400869 [00:01<00:00, 389695.29B/s]\n","output_type":"stream"},{"name":"stdout","text":"downloading https://nlp.h-its.org/bpemb/en/en.wiki.bpe.vs10000.d100.w2v.bin.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3784656/3784656 [00:01<00:00, 2160415.10B/s]\n","output_type":"stream"},{"name":"stdout","text":"downloading https://nlp.h-its.org/bpemb/hi/hi.wiki.bpe.vs10000.model\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 463471/463471 [00:01<00:00, 459389.69B/s]\n","output_type":"stream"},{"name":"stdout","text":"downloading https://nlp.h-its.org/bpemb/hi/hi.wiki.bpe.vs10000.d100.w2v.bin.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 3796553/3796553 [00:01<00:00, 1975583.13B/s]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"## dataset and dataloader","metadata":{}},{"cell_type":"code","source":"class CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, data, max_seq_len=64):\n        super(CustomDataset, self).__init__()\n        self.data = data\n        self.max_seq_len = max_seq_len\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        eng_sen = self.data.english.iloc[index]\n        hin_sen = self.data.hindi.iloc[index]\n        eng_tokens = bpemb_en.encode_ids_with_bos_eos(eng_sen)\n        hin_tokens = bpemb_hi.encode_ids_with_bos_eos(hin_sen)\n        trg_input_tokens = hin_tokens[:-1]\n        trg_output_tokens = hin_tokens[1:]\n        \n        eng_mask = [1]*(len(eng_tokens))\n        hin_mask = [1]*(len(trg_input_tokens))\n        \n        eng_tokens = eng_tokens + [0]*(self.max_seq_len - len(eng_tokens))\n        trg_input_tokens = trg_input_tokens + [0]*(self.max_seq_len - len(trg_input_tokens))\n        trg_output_tokens = trg_output_tokens + [0]*(self.max_seq_len - len(trg_output_tokens))\n        \n        eng_mask = eng_mask + [0]*(self.max_seq_len - len(eng_mask))\n        hin_mask = hin_mask + [0]*(self.max_seq_len - len(hin_mask))\n        # pad eng_tokens upto max_seq_len\n        # pad_hin_tokens upto max_seq_len\n        # then create masks for both of the inputs, and make them upto the dimension needed\n        \n        # now we have to pad the sequence upto max length and create the masks for the same\n        \n        \n        return torch.tensor(eng_tokens), torch.tensor(trg_input_tokens), torch.tensor(trg_output_tokens), torch.tensor(eng_mask), torch.tensor(hin_mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:17:50.371151Z","iopub.execute_input":"2024-11-17T08:17:50.371916Z","iopub.status.idle":"2024-11-17T08:17:50.382297Z","shell.execute_reply.started":"2024-11-17T08:17:50.371872Z","shell.execute_reply":"2024-11-17T08:17:50.381349Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"## encoder , decoder and attention mechanism","metadata":{}},{"cell_type":"code","source":"def scaled_dot_product_attention(query, key, value, mask=None):\n    # this is going in the single head self-attention.\n    # query, key, value shape will be (b, h, t, d/h) \n    d_k = query.shape[-1]\n    scaled_scores = torch.matmul(query, torch.transpose(key, -2, -1))/np.sqrt(d_k)  # shape is  (b, h, t, t)\n    \n    if mask is not None:\n        # mask must be of shape (b,h,t,t)\n        scaled_scores = torch.where(mask==0, -np.inf, scaled_scores)\n        \n    weights = torch.nn.Softmax(dim=-1)(scaled_scores) # shape is (b,h,t,t)\n    return torch.matmul(weights, value)  # shape will be (b,h,t,d/h)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:19:04.180118Z","iopub.execute_input":"2024-11-17T08:19:04.180814Z","iopub.status.idle":"2024-11-17T08:19:04.187439Z","shell.execute_reply.started":"2024-11-17T08:19:04.180763Z","shell.execute_reply":"2024-11-17T08:19:04.186337Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# this is an example of how multi-head works\nb = 1\nt = 3\nd = 12\nh = 3\n# first assigning the weights\nwq0 = torch.rand((d, d//h))\nwk0 = torch.rand((d, d//h))\nwv0 = torch.rand((d, d//h))\n\nwq1 = torch.rand((d, d//h))\nwk1 = torch.rand((d, d//h))\nwv1 = torch.rand((d, d//h))\n\nwq2 = torch.rand((d, d//h))\nwk2 = torch.rand((d, d//h))\nwv2 = torch.rand((d, d//h))\n\n# let us take some random input also \nx = torch.rand((1, t, d))\n\n# now calculating q, k, v for each attention head\nq0 = torch.matmul(x, wq0)\nk0 = torch.matmul(x, wk0)\nv0 = torch.matmul(x, wv0)\n\nq1 = torch.matmul(x, wq1)\nk1 = torch.matmul(x, wk1)\nv1 = torch.matmul(x, wv1)\n\nq2 = torch.matmul(x, wq2)\nk2 = torch.matmul(x, wk2)\nv2 = torch.matmul(x, wv2)\n\n# now we have to perform scaled self-attention on each head\nop0 = scaled_dot_product_attention(q0, k0, v0)\nop1 = scaled_dot_product_attention(q1, k1, v1)\nop2 = scaled_dot_product_attention(q2, k2, v2)\n\n\n# now the final ouputu is the conactenation of all the three outputs\nop = torch.concat([op0, op1, op2], dim=2)\nprint(op.shape)\nprint(op)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:19:22.004970Z","iopub.execute_input":"2024-11-17T08:19:22.005603Z","iopub.status.idle":"2024-11-17T08:19:22.187110Z","shell.execute_reply.started":"2024-11-17T08:19:22.005562Z","shell.execute_reply":"2024-11-17T08:19:22.186051Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 3, 12])\ntensor([[[4.2392, 3.9870, 4.9238, 3.2736, 3.2142, 3.9222, 4.1703, 4.6155,\n          4.0666, 4.7017, 3.9342, 3.5006],\n         [4.2389, 3.9866, 4.9229, 3.2733, 3.2142, 3.9221, 4.1702, 4.6154,\n          4.0466, 4.6776, 3.9209, 3.4825],\n         [4.2383, 3.9859, 4.9217, 3.2727, 3.2140, 3.9218, 4.1700, 4.6153,\n          4.0105, 4.6341, 3.8968, 3.4500]]])\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# but we don't have to do this multi-headed attention by calculating different heads, so let us first of all \n# concatenate the weights of the self attention \nwq = torch.concat([wq0, wq1, wq2], axis=1)\nwk = torch.concat([wk0, wk1, wk2], axis=1)\nwv = torch.concat([wv0, wv1, wv2], axis=1)\n\n# now we have to get the q,k ,v\nq = torch.matmul(x, wq)\nk = torch.matmul(x, wk)\nv = torch.matmul(x, wv)\n\n# and finally we have to do the self-attention \nprint(q0, '\\n')\nprint(q1, '\\n')\nprint(q2, '\\n')\nprint(q)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:19:39.801835Z","iopub.execute_input":"2024-11-17T08:19:39.802243Z","iopub.status.idle":"2024-11-17T08:19:39.813519Z","shell.execute_reply.started":"2024-11-17T08:19:39.802204Z","shell.execute_reply":"2024-11-17T08:19:39.812516Z"}},"outputs":[{"name":"stdout","text":"tensor([[[3.9438, 3.8335, 4.6411, 4.9659],\n         [3.3887, 2.1897, 3.6973, 3.6439],\n         [2.6640, 2.4181, 3.1155, 3.0308]]]) \n\ntensor([[[4.4655, 6.2410, 4.1343, 4.0531],\n         [3.6420, 3.6887, 2.8314, 3.2289],\n         [3.0581, 3.5235, 2.6255, 2.7128]]]) \n\ntensor([[[3.8300, 3.3751, 3.0031, 5.1045],\n         [3.0232, 2.5517, 2.0502, 3.5196],\n         [2.8088, 1.7579, 1.7806, 3.1562]]]) \n\ntensor([[[3.9438, 3.8335, 4.6411, 4.9659, 4.4655, 6.2410, 4.1343, 4.0531,\n          3.8300, 3.3751, 3.0031, 5.1045],\n         [3.3887, 2.1897, 3.6973, 3.6439, 3.6420, 3.6887, 2.8314, 3.2289,\n          3.0232, 2.5517, 2.0502, 3.5196],\n         [2.6640, 2.4181, 3.1155, 3.0308, 3.0581, 3.5235, 2.6255, 2.7128,\n          2.8088, 1.7579, 1.7806, 3.1562]]])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# now we have to do operations on q such that we get q0, q1, q2 from q\nq = q.reshape(b, t, h, d//h).permute(0, 2, 1, 3)\nk = k.reshape(b, t, h, d//h).permute(0, 2, 1, 3)\nv = v.reshape(b, t, h, d//h).permute(0, 2, 1, 3)\n\nop_multi = scaled_dot_product_attention(q, k, v)\nop, op_multi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:19:58.361650Z","iopub.execute_input":"2024-11-17T08:19:58.362055Z","iopub.status.idle":"2024-11-17T08:19:58.373716Z","shell.execute_reply.started":"2024-11-17T08:19:58.362017Z","shell.execute_reply":"2024-11-17T08:19:58.372752Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(tensor([[[4.2392, 3.9870, 4.9238, 3.2736, 3.2142, 3.9222, 4.1703, 4.6155,\n           4.0666, 4.7017, 3.9342, 3.5006],\n          [4.2389, 3.9866, 4.9229, 3.2733, 3.2142, 3.9221, 4.1702, 4.6154,\n           4.0466, 4.6776, 3.9209, 3.4825],\n          [4.2383, 3.9859, 4.9217, 3.2727, 3.2140, 3.9218, 4.1700, 4.6153,\n           4.0105, 4.6341, 3.8968, 3.4500]]]),\n tensor([[[[4.2392, 3.9870, 4.9238, 3.2736],\n           [4.2389, 3.9866, 4.9229, 3.2733],\n           [4.2383, 3.9859, 4.9217, 3.2727]],\n \n          [[3.2142, 3.9222, 4.1703, 4.6155],\n           [3.2142, 3.9221, 4.1702, 4.6154],\n           [3.2140, 3.9218, 4.1700, 4.6153]],\n \n          [[4.0666, 4.7017, 3.9342, 3.5006],\n           [4.0466, 4.6776, 3.9209, 3.4825],\n           [4.0105, 4.6341, 3.8968, 3.4500]]]]))"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"op_multi.permute(0, 2, 1, 3).reshape(b, t, d)==op","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:20:11.633635Z","iopub.execute_input":"2024-11-17T08:20:11.634339Z","iopub.status.idle":"2024-11-17T08:20:11.642600Z","shell.execute_reply.started":"2024-11-17T08:20:11.634268Z","shell.execute_reply":"2024-11-17T08:20:11.641623Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n          True],\n         [True, True, True, True, True, True, True, True, True, True, True,\n          True],\n         [True, True, True, True, True, True, True, True, True, True, True,\n          True]]])"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## model training ","metadata":{}},{"cell_type":"code","source":"class MultiHeadSelfAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadSelfAttention, self).__init__()\n        self.d_model = d_model\n        self.num_heads = num_heads\n        \n        # let us say that our input is of shape (b, t, d) \n        self.wq = nn.Linear(in_features = self.d_model, out_features = self.d_model, bias = False) \n        self.wk = nn.Linear(in_features = self.d_model, out_features = self.d_model, bias = False)\n        self.wv = nn.Linear(in_features = self.d_model, out_features = self.d_model, bias = False)\n        # remember that wq, wk, ev defined above are just the matrices nothing more\n        \n        # now the final dense layer to add some nolinearity in it \n        self.fc = nn.Linear(self.d_model, self.d_model)\n        \n    def forward(self, q, k, v, mask=None):\n        # shape of q, k, v is (b, t, d)\n        q = self.wq(q).reshape(q.shape[0], q.shape[1], self.num_heads, self.d_model//self.num_heads).permute(0, 2, 1, 3) \n        k = self.wk(k).reshape(k.shape[0], k.shape[1], self.num_heads, self.d_model//self.num_heads).permute(0, 2, 1, 3) \n        v = self.wv(v).reshape(v.shape[0], v.shape[1], self.num_heads, self.d_model//self.num_heads).permute(0, 2, 1, 3) \n        \n        # now shape of q, k, v is (b, h, t, d/h)\n        # now we have to simply perform  self-attention for every head\n        op = scaled_dot_product_attention(q, k, v, mask)  # shape of op is (b, h, t, d/h)\n        op = op.permute(0, 2, 1, 3)\n        op = op.reshape(op.shape[0], op.shape[1], self.d_model)  # now shape of op is (b, t, d)\n        return self.fc(op) # shapes are (b, t, d)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:20:39.385548Z","iopub.execute_input":"2024-11-17T08:20:39.386378Z","iopub.status.idle":"2024-11-17T08:20:39.396961Z","shell.execute_reply.started":"2024-11-17T08:20:39.386334Z","shell.execute_reply":"2024-11-17T08:20:39.395873Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class feedforward(nn.Module):\n    def __init__(self, d_model, hidden_dim):\n        super(feedforward, self).__init__()\n        self.fc1 = nn.Linear(d_model, hidden_dim)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(hidden_dim, d_model)\n        \n    def forward(self, x):\n        return self.fc2(self.relu(self.fc1(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:20:49.966687Z","iopub.execute_input":"2024-11-17T08:20:49.967494Z","iopub.status.idle":"2024-11-17T08:20:49.973178Z","shell.execute_reply.started":"2024-11-17T08:20:49.967452Z","shell.execute_reply":"2024-11-17T08:20:49.972263Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class encoder_block(nn.Module):\n    def __init__(self, d_model, num_heads, hidden_dim, dropout_rate=0.1):\n        super(encoder_block, self).__init__()\n        self.mhsa = MultiHeadSelfAttention(d_model, num_heads)\n        self.fc = feedforward(d_model, hidden_dim) # gonna give the shapes again to be (b, t, d)\n        \n        self.dropout1 = nn.Dropout(p=dropout_rate)\n        self.dropout2 = nn.Dropout(p=dropout_rate)\n        \n        self.layernorm1 = nn.LayerNorm(d_model)\n        self.layernorm2 = nn.LayerNorm(d_model)\n    \n    def forward(self, x, mask=None):\n        # input shape is (b, t, d)\n        op = self.mhsa(x, x, x, mask) # op shape is (b, t, d) and attention weights are of shape (b, t, t)\n        op = self.dropout1(op)\n        # now we have to pass it through layer normalization (study it)\n        op = self.layernorm1(op + x)\n        ffn_op = self.fc(op)\n        ffn_op = self.dropout2(ffn_op)\n        op = self.layernorm2(op + ffn_op)\n        return op","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:21:02.974799Z","iopub.execute_input":"2024-11-17T08:21:02.975801Z","iopub.status.idle":"2024-11-17T08:21:02.983352Z","shell.execute_reply.started":"2024-11-17T08:21:02.975761Z","shell.execute_reply":"2024-11-17T08:21:02.982448Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class encoder_transformer(nn.Module):\n    def __init__(self, num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, max_seq_len, dropout_rate=0.1):\n        # max_seq_len is the number of time steps, i'll be referring it as t\n        super(encoder_transformer, self).__init__()\n        self.num_blocks = num_blocks\n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.hidden_dim = hidden_dim \n        self.vocab_size = src_vocab_size\n        self.max_seq_len = max_seq_len\n        \n        self.token_embeds = nn.Embedding(src_vocab_size, d_model)\n        self.pos_embeds = nn.Embedding(max_seq_len, d_model)\n        self.dropout = nn.Dropout(p = dropout_rate)\n        self.blocks = nn.ModuleList([encoder_block(d_model, num_heads, hidden_dim, dropout_rate=dropout_rate) \n                      for _ in range(self.num_blocks)])\n        \n            \n        \n        \n    \n    def forward(self, source, mask=None):\n        # shape of source is (b, t)\n        # all source sentences will be padded and padding will be static\n        source = source.type(torch.LongTensor).to(device)\n        # comment out above line for \n        t_embeds = self.token_embeds(source) # (b, t, d)\n        pos_ids = torch.broadcast_to(torch.arange(self.max_seq_len), (x.shape[0], self.max_seq_len)).type(torch.LongTensor\n                                                                                                         ).to(device)\n        p_embeds = self.pos_embeds(pos_ids) # (b, t, d)\n        \n        inp = t_embeds + p_embeds  # (b, t, d)\n        op = self.dropout(inp)  # (b, t, d)\n        \n        for _, block in enumerate(self.blocks):\n            op = block(op, mask)\n            \n        return op","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:21:17.893285Z","iopub.execute_input":"2024-11-17T08:21:17.894037Z","iopub.status.idle":"2024-11-17T08:21:17.904249Z","shell.execute_reply.started":"2024-11-17T08:21:17.893993Z","shell.execute_reply":"2024-11-17T08:21:17.903272Z"}},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"## decoder","metadata":{}},{"cell_type":"code","source":"class decoder_block(nn.Module):\n    def __init__(self, d_model, num_heads, hidden_dim, dropout_rate=0.1):\n        super(decoder_block, self).__init__()\n        self.mhsa1 = MultiHeadSelfAttention(d_model, num_heads)\n        self.mhsa2 = MultiHeadSelfAttention(d_model, num_heads)\n        \n        self.fc = feedforward(d_model, hidden_dim)\n        \n        self.dropout1 = nn.Dropout(p=dropout_rate)\n        self.dropout2 = nn.Dropout(p=dropout_rate)\n        self.dropout3 = nn.Dropout(p=dropout_rate)\n        \n        self.layernorm1 = nn.LayerNorm(d_model)\n        self.layernorm2 = nn.LayerNorm(d_model)\n        self.layernorm3 = nn.LayerNorm(d_model)\n        \n        \n    def forward(self, encoder_ouptut, target, decoder_mask=None, memory_mask=None):\n        mhsa_op1 = self.mhsa1(target, target, target, decoder_mask)\n        mhsa_op1 = self.dropout1(mhsa_op1)\n        mhsa_op1 = self.layernorm1(mhsa_op1 + target)\n        \n        mhsa_op2 = self.mhsa2(mhsa_op1, encoder_ouptut, encoder_ouptut, memory_mask)\n        mhsa_op2 = self.dropout2(mhsa_op2)\n        mhsa_op2 = self.layernorm2(mhsa_op1 + mhsa_op2)\n        \n        fc_op = self.fc(mhsa_op2)\n        fc_op = self.dropout3(fc_op)\n        op = self.layernorm3(fc_op + mhsa_op2)\n        \n        return op","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:21:47.379231Z","iopub.execute_input":"2024-11-17T08:21:47.379670Z","iopub.status.idle":"2024-11-17T08:21:47.389569Z","shell.execute_reply.started":"2024-11-17T08:21:47.379632Z","shell.execute_reply":"2024-11-17T08:21:47.388428Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"class decoder_transformer(nn.Module):\n    def __init__(self, num_blocks, d_model, num_heads, hidden_dim, trg_vocab_size, max_seq_len, dropout_rate=0.1):\n        super(decoder_transformer, self).__init__()\n        self.token_embeds = nn.Embedding(trg_vocab_size, d_model)\n        self.pos_embeds = nn.Embedding(max_seq_len, d_model)\n        self.max_seq_len = max_seq_len\n        self.dropout = nn.Dropout(p=dropout_rate)\n        \n        self.blocks = nn.ModuleList([decoder_block(d_model, num_heads, hidden_dim, dropout_rate) \n                                    for _ in range(num_blocks)])\n    \n    def forward(self, encoder_output, target, decoder_mask=None, memory_mask=None):\n        # shape of target is (b, t)\n        target = target.type(torch.LongTensor).to(device)\n        t_embeds = self.token_embeds(target) # (b, t, d)\n        pos_ids = torch.broadcast_to(torch.arange(self.max_seq_len), (x.shape[0], self.max_seq_len)).type(torch.LongTensor\n                                                                                                         ).to(device)\n        p_embeds = self.pos_embeds(pos_ids)  # (b, t, d)\n        \n        inp = t_embeds + p_embeds\n        op = self.dropout(inp)\n        # now op is (b, t, d)\n        \n        for _, block in enumerate(self.blocks):\n            op = block(encoder_output, op, decoder_mask, memory_mask)\n            \n        return op","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:22:01.841911Z","iopub.execute_input":"2024-11-17T08:22:01.842800Z","iopub.status.idle":"2024-11-17T08:22:01.852148Z","shell.execute_reply.started":"2024-11-17T08:22:01.842758Z","shell.execute_reply":"2024-11-17T08:22:01.850987Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class transformer(nn.Module):\n    def __init__(self, num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, trg_vocab_size, max_seq_len, \n                dropout_rate=0.1):\n        super(transformer, self).__init__()\n        self.encoder = encoder_transformer(num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, max_seq_len,\n                            dropout_rate=0.1)\n        self.decoder = decoder_transformer(num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, max_seq_len,\n                            dropout_rate=0.1)\n        \n        self.fc = nn.Linear(d_model, trg_vocab_size)\n        self.lookahead = torch.tril(torch.ones((max_seq_len, max_seq_len))).to(device)\n    \n    def forward(self, src, trg, src_pad_mask=None, trg_pad_mask=None):\n        # we require masks to be of shape (b, 1, 1, t)\n        dec_mask = None\n        if src_pad_mask is not None:\n            src_pad_mask = src_pad_mask.unsqueeze(1).unsqueeze(1)\n            src_pad_mask = src_pad_mask.to(device)\n        if trg_pad_mask is not None:\n            trg_pad_mask = trg_pad_mask.unsqueeze(1).unsqueeze(1)\n            dec_mask = torch.minimum(trg_pad_mask, self.lookahead)\n            dec_mask = dec_mask.to(device)\n            \n        enc_op = self.encoder(src, src_pad_mask)\n        op = self.decoder(enc_op, trg, dec_mask, src_pad_mask) # op is of shape (b, t, d)\n        # and generate the required look ahead mask\n        op = op.reshape(-1, op.shape[-1]) # shape is (b*t, d)\n        op = self.fc(op) # shape is (b*t, trg_vocab_size)\n        \n        return op","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:22:18.033825Z","iopub.execute_input":"2024-11-17T08:22:18.034201Z","iopub.status.idle":"2024-11-17T08:22:18.044725Z","shell.execute_reply.started":"2024-11-17T08:22:18.034166Z","shell.execute_reply":"2024-11-17T08:22:18.043728Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"## utils ","metadata":{}},{"cell_type":"code","source":"def BLEU():\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:22:43.189628Z","iopub.execute_input":"2024-11-17T08:22:43.190052Z","iopub.status.idle":"2024-11-17T08:22:43.194751Z","shell.execute_reply.started":"2024-11-17T08:22:43.190014Z","shell.execute_reply":"2024-11-17T08:22:43.193761Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def METEOR():\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:22:51.472952Z","iopub.execute_input":"2024-11-17T08:22:51.473904Z","iopub.status.idle":"2024-11-17T08:22:51.477948Z","shell.execute_reply.started":"2024-11-17T08:22:51.473862Z","shell.execute_reply":"2024-11-17T08:22:51.476887Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def save_checkpoint(state, filename='my_checkpoint.pth'):\n    # will save model and optimizer params at every epoch\n    print(\"-> Saving CheckPoint\")\n    torch.save(state, filename)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:23:01.380526Z","iopub.execute_input":"2024-11-17T08:23:01.381459Z","iopub.status.idle":"2024-11-17T08:23:01.385851Z","shell.execute_reply.started":"2024-11-17T08:23:01.381417Z","shell.execute_reply":"2024-11-17T08:23:01.384854Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def load_checkpoint(checkpoint, model):\n    # it will just load, we can train it further, make changes to the architecture\n    # and simply use it to predict\n    print(\"-> Loading CheckPoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:23:11.902086Z","iopub.execute_input":"2024-11-17T08:23:11.902494Z","iopub.status.idle":"2024-11-17T08:23:11.907239Z","shell.execute_reply.started":"2024-11-17T08:23:11.902456Z","shell.execute_reply":"2024-11-17T08:23:11.906217Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def train(loader, model, optimizer, scaler, scheduler, loss_fn, epoch, device=device):\n    '''\n    it is the training procedure for one epoch of the network\n    '''\n    losses = 0\n    model.train()\n    num_batches = len(loader)\n    batches = tqdm(loader) # tqdm will be used to generate progress bars\n    for idx, batch in enumerate(batches, 0):\n        src = batch[0].to(device)  # (batch_size, max_len)\n        trg_inp = batch[1].to(device)  # (batch_size, max_len)\n        trg_op = batch[2].to(device) # (batch_size, max_len)\n        src_pad_mask = batch[3].to(device) # (batch_size, max_len)\n        trg_pad_mask = batch[4].to(device) # (batch_size, max_len)\n\n        # forward\n        optimizer.zero_grad()\n        with torch.cuda.amp.autocast(): # for gradient underflowing and overflowing and it makes training faster by converting all floats to float16\n            op = model(src, trg_inp, src_pad_mask, trg_pad_mask) # op shape is (batch_size*max_len, trg_vocab_size+1)\n            trg_op = trg_op.reshape(trg_op.shape[0]*trg_op.shape[1]) # trg_op shape is (batch_size*max_len)\n            loss = loss_fn(op, trg_op) # loss_fn should contain the parametere ignore_idx=0, so that \n            # losses corresponding to the padding token isn't calculated\n\n        # making all the previous gradients zero \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        batches.set_postfix(loss = loss.item(), epoch=epoch) # loss of this current batch on current iteration \n        losses+= loss.item()\n\n    losses/=num_batches    \n    #scheduler.step()\n    return losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:24:02.805300Z","iopub.execute_input":"2024-11-17T08:24:02.805733Z","iopub.status.idle":"2024-11-17T08:24:02.816530Z","shell.execute_reply.started":"2024-11-17T08:24:02.805689Z","shell.execute_reply":"2024-11-17T08:24:02.815517Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"def test():\n    # i will only use this function for measuring its accuracy on different metrics\n    # for this task such as meteor and bleu\n    pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:24:19.784460Z","iopub.execute_input":"2024-11-17T08:24:19.785247Z","iopub.status.idle":"2024-11-17T08:24:19.789461Z","shell.execute_reply.started":"2024-11-17T08:24:19.785206Z","shell.execute_reply":"2024-11-17T08:24:19.788494Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def translate_sentence(sentence, model, max_seq_len, trans_len=50):\n    model.eval()\n    # first i am given the english sentence\n    inp = bpemb_en.encode_ids_with_bos_eos(sentence)\n    enc_mask = [1]*(len(inp))\n    inp = inp + [0]*(max_seq_len - len(inp))\n    enc_mask = enc_mask + [0]*(max_seq_len - len(enc_mask))\n    # inp shape is (max_seq_len) and so is of mask\n    #print(f'input = {inp}\\n\\nmask = {enc_mask}')\n    inp = torch.tensor(inp).unsqueeze(0).to(device) # shape of input is (1, max_seq_len)\n    enc_mask = torch.tensor(enc_mask).unsqueeze(0).to(device) # shape of mask is also (1, max_seq_len)\n    #inp =  inp.unsqueeze(0)\n    #enc_mask = enc_mask.unsqueeze(0).unsqueeze(1).unsqueeze(1) #  shape should be (b,1,1,max_seq_len)\n    # now the shapes are as required by the transformer\n    \n    #enc_op = model.encoder(inp, enc_mask)\n    # now we have to decode the sentence one-by-one \n    # so let us first of all make the inputs and the corresponding trg_mask\n    trg_inp = torch.zeros(max_seq_len).unsqueeze(0).to(device) # shape is (1, max_seq_len)\n    trg_mask = torch.zeros(max_seq_len).unsqueeze(0).to(device) # shape is (1, max_seq_len)\n    \n    #lookahead = torch.tril(torch.ones((max_seq_len, max_seq_len))).to(device) \n    \n    trg_inp[0, 0] = 1 # 1 means <sos> token\n    translation = []\n    #trg_mask[0, 0, 0, len(translation)] = 1 # as trg_inp has only one word in it at current time step\n    #dec_mask = torch.minimum(trg_mask, lookahead)\n    trg_mask[0, len(translation)] = 1 # as trg_inp has only one word in it at current time step\n    last_token = trg_inp[0, len(translation)]\n    # now we have to pass it through a decoder until we get a <eos> token or we exceed trans_len\n    while len(translation)<trans_len and last_token!=2: # 2 means <eos> token\n        # now we have to pass the above inputs through decoder\n        #dec_op = model.decoder(enc_op, trg_inp, dec_mask, enc_mask) \n        # now shape of decoder op will be \n        # shape of output is (1, hindi_vocab_size)\n        op = model(inp, trg_inp, enc_mask, trg_mask) # shape of op will be (max_seq_len, trg_vocab_size)\n        op = op.argmax(dim=1)  # shape will be (max_seq_len)\n        last_token = op[len(translation)].item()\n        translation.append(last_token)\n        trg_inp[0, len(translation)] = last_token  # updating the last token in the trg_inp\n        trg_mask[0, len(translation)] = 1  # setting up the mask for the current value equal to 1\n        #print(f\"DONE {len(translation)} times\")\n        \n    model.train()\n    return bpemb_hi.decode(translation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:24:32.597616Z","iopub.execute_input":"2024-11-17T08:24:32.598529Z","iopub.status.idle":"2024-11-17T08:24:32.609093Z","shell.execute_reply.started":"2024-11-17T08:24:32.598480Z","shell.execute_reply":"2024-11-17T08:24:32.608139Z"}},"outputs":[],"execution_count":31},{"cell_type":"markdown","source":"## driver code","metadata":{}},{"cell_type":"code","source":"# training hyperparameters\nnum_epochs =  20\nlr = 3e-4\nbatch_size = 64\n\ntrain_dataset = CustomDataset(train_split, max_seq_len=64)\ntest_dataset = CustomDataset(test_split, max_seq_len=64)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:24:59.448877Z","iopub.execute_input":"2024-11-17T08:24:59.449238Z","iopub.status.idle":"2024-11-17T08:24:59.455614Z","shell.execute_reply.started":"2024-11-17T08:24:59.449205Z","shell.execute_reply":"2024-11-17T08:24:59.454510Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# model hyperparameters\nnum_blocks = 3\nd_model = 512\nnum_heads = 8\nhidden_dim = 4*d_model\nsrc_vocab_size = bpemb_en.vocab_size + 1 # +1 due to padding token\ntrg_vocab_size = bpemb_hi.vocab_size + 1 # +1 due to padding token\nmax_seq_len = 64\n\n# testing the model\nmodel = transformer(num_blocks, d_model, num_heads, hidden_dim, src_vocab_size, \n                              trg_vocab_size, max_seq_len).to(device)\nsummary(model, [(max_seq_len, ), (max_seq_len ,)])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:25:09.494664Z","iopub.execute_input":"2024-11-17T08:25:09.495039Z","iopub.status.idle":"2024-11-17T08:25:10.413093Z","shell.execute_reply.started":"2024-11-17T08:25:09.495007Z","shell.execute_reply":"2024-11-17T08:25:10.412144Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n         Embedding-1              [-1, 64, 512]       5,120,512\n         Embedding-2              [-1, 64, 512]          32,768\n           Dropout-3              [-1, 64, 512]               0\n            Linear-4              [-1, 64, 512]         262,144\n            Linear-5              [-1, 64, 512]         262,144\n            Linear-6              [-1, 64, 512]         262,144\n            Linear-7              [-1, 64, 512]         262,656\nMultiHeadSelfAttention-8              [-1, 64, 512]               0\n           Dropout-9              [-1, 64, 512]               0\n        LayerNorm-10              [-1, 64, 512]           1,024\n           Linear-11             [-1, 64, 2048]       1,050,624\n             ReLU-12             [-1, 64, 2048]               0\n           Linear-13              [-1, 64, 512]       1,049,088\n      feedforward-14              [-1, 64, 512]               0\n          Dropout-15              [-1, 64, 512]               0\n        LayerNorm-16              [-1, 64, 512]           1,024\n    encoder_block-17              [-1, 64, 512]               0\n           Linear-18              [-1, 64, 512]         262,144\n           Linear-19              [-1, 64, 512]         262,144\n           Linear-20              [-1, 64, 512]         262,144\n           Linear-21              [-1, 64, 512]         262,656\nMultiHeadSelfAttention-22              [-1, 64, 512]               0\n          Dropout-23              [-1, 64, 512]               0\n        LayerNorm-24              [-1, 64, 512]           1,024\n           Linear-25             [-1, 64, 2048]       1,050,624\n             ReLU-26             [-1, 64, 2048]               0\n           Linear-27              [-1, 64, 512]       1,049,088\n      feedforward-28              [-1, 64, 512]               0\n          Dropout-29              [-1, 64, 512]               0\n        LayerNorm-30              [-1, 64, 512]           1,024\n    encoder_block-31              [-1, 64, 512]               0\n           Linear-32              [-1, 64, 512]         262,144\n           Linear-33              [-1, 64, 512]         262,144\n           Linear-34              [-1, 64, 512]         262,144\n           Linear-35              [-1, 64, 512]         262,656\nMultiHeadSelfAttention-36              [-1, 64, 512]               0\n          Dropout-37              [-1, 64, 512]               0\n        LayerNorm-38              [-1, 64, 512]           1,024\n           Linear-39             [-1, 64, 2048]       1,050,624\n             ReLU-40             [-1, 64, 2048]               0\n           Linear-41              [-1, 64, 512]       1,049,088\n      feedforward-42              [-1, 64, 512]               0\n          Dropout-43              [-1, 64, 512]               0\n        LayerNorm-44              [-1, 64, 512]           1,024\n    encoder_block-45              [-1, 64, 512]               0\nencoder_transformer-46              [-1, 64, 512]               0\n        Embedding-47              [-1, 64, 512]       5,120,512\n        Embedding-48              [-1, 64, 512]          32,768\n          Dropout-49              [-1, 64, 512]               0\n           Linear-50              [-1, 64, 512]         262,144\n           Linear-51              [-1, 64, 512]         262,144\n           Linear-52              [-1, 64, 512]         262,144\n           Linear-53              [-1, 64, 512]         262,656\nMultiHeadSelfAttention-54              [-1, 64, 512]               0\n          Dropout-55              [-1, 64, 512]               0\n        LayerNorm-56              [-1, 64, 512]           1,024\n           Linear-57              [-1, 64, 512]         262,144\n           Linear-58              [-1, 64, 512]         262,144\n           Linear-59              [-1, 64, 512]         262,144\n           Linear-60              [-1, 64, 512]         262,656\nMultiHeadSelfAttention-61              [-1, 64, 512]               0\n          Dropout-62              [-1, 64, 512]               0\n        LayerNorm-63              [-1, 64, 512]           1,024\n           Linear-64             [-1, 64, 2048]       1,050,624\n             ReLU-65             [-1, 64, 2048]               0\n           Linear-66              [-1, 64, 512]       1,049,088\n      feedforward-67              [-1, 64, 512]               0\n          Dropout-68              [-1, 64, 512]               0\n        LayerNorm-69              [-1, 64, 512]           1,024\n    decoder_block-70              [-1, 64, 512]               0\n           Linear-71              [-1, 64, 512]         262,144\n           Linear-72              [-1, 64, 512]         262,144\n           Linear-73              [-1, 64, 512]         262,144\n           Linear-74              [-1, 64, 512]         262,656\nMultiHeadSelfAttention-75              [-1, 64, 512]               0\n          Dropout-76              [-1, 64, 512]               0\n        LayerNorm-77              [-1, 64, 512]           1,024\n           Linear-78              [-1, 64, 512]         262,144\n           Linear-79              [-1, 64, 512]         262,144\n           Linear-80              [-1, 64, 512]         262,144\n           Linear-81              [-1, 64, 512]         262,656\nMultiHeadSelfAttention-82              [-1, 64, 512]               0\n          Dropout-83              [-1, 64, 512]               0\n        LayerNorm-84              [-1, 64, 512]           1,024\n           Linear-85             [-1, 64, 2048]       1,050,624\n             ReLU-86             [-1, 64, 2048]               0\n           Linear-87              [-1, 64, 512]       1,049,088\n      feedforward-88              [-1, 64, 512]               0\n          Dropout-89              [-1, 64, 512]               0\n        LayerNorm-90              [-1, 64, 512]           1,024\n    decoder_block-91              [-1, 64, 512]               0\n           Linear-92              [-1, 64, 512]         262,144\n           Linear-93              [-1, 64, 512]         262,144\n           Linear-94              [-1, 64, 512]         262,144\n           Linear-95              [-1, 64, 512]         262,656\nMultiHeadSelfAttention-96              [-1, 64, 512]               0\n          Dropout-97              [-1, 64, 512]               0\n        LayerNorm-98              [-1, 64, 512]           1,024\n           Linear-99              [-1, 64, 512]         262,144\n          Linear-100              [-1, 64, 512]         262,144\n          Linear-101              [-1, 64, 512]         262,144\n          Linear-102              [-1, 64, 512]         262,656\nMultiHeadSelfAttention-103              [-1, 64, 512]               0\n         Dropout-104              [-1, 64, 512]               0\n       LayerNorm-105              [-1, 64, 512]           1,024\n          Linear-106             [-1, 64, 2048]       1,050,624\n            ReLU-107             [-1, 64, 2048]               0\n          Linear-108              [-1, 64, 512]       1,049,088\n     feedforward-109              [-1, 64, 512]               0\n         Dropout-110              [-1, 64, 512]               0\n       LayerNorm-111              [-1, 64, 512]           1,024\n   decoder_block-112              [-1, 64, 512]               0\ndecoder_transformer-113              [-1, 64, 512]               0\n          Linear-114                [-1, 10001]       5,130,513\n================================================================\nTotal params: 37,492,497\nTrainable params: 37,492,497\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.02\nForward/backward pass size (MB): 37.33\nParams size (MB): 143.02\nEstimated Total Size (MB): 180.36\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# let us test our model on some actual input to check it doesn't break\nfor _, batch in enumerate(train_loader):\n    src = batch[0][0].unsqueeze(0).to(device)\n    trg_inp = batch[1][0].unsqueeze(0).to(device)\n    trg_op = batch[2][0].unsqueeze(0).to(device)\n    src_pad_mask = batch[3][0].unsqueeze(0).to(device)\n    trg_pad_mask = batch[4][0].unsqueeze(0).to(device)\n    break\n    \n#print(f'{src}\\n\\n{src_pad_mask}\\n\\n{trg}\\n\\n{trg_pad_mask}')\nop = model(src, trg_inp, src_pad_mask, trg_pad_mask)\nop = nn.Softmax(dim=-1)(op)\nout = torch.max(op, dim=-1).indices\nprint(f'Original English Sentence {bpemb_en.decode(src.tolist())}\\n\\nOriginal Hindi Sentence {bpemb_hi.decode(trg_inp.tolist())}\\n\\nPredicted Sentence {bpemb_hi.decode(out.tolist())}')\n# ?? are because of the padding tokens we can easily remove them when needed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:26:05.457336Z","iopub.execute_input":"2024-11-17T08:26:05.458131Z","iopub.status.idle":"2024-11-17T08:26:05.622725Z","shell.execute_reply.started":"2024-11-17T08:26:05.458087Z","shell.execute_reply":"2024-11-17T08:26:05.621748Z"}},"outputs":[{"name":"stdout","text":"Original English Sentence ['and whosoever is in the earth, altogether, so that it might save him. ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ ']\n\nOriginal Hindi Sentence ['और जितने आदमी ज़मीन पर हैं सब को ले ले और उसको छुटकारा दे दें ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇  ⁇ ']\n\nPredicted Sentence ['बिन', 'पथ', 'माइक्र', 'हिस्से', '’', 'गुलाब', 'ब्दिक', 'class', 'अर', 'छुट', 'स्कॉ', 'वाइ', 'खंड', 'दिख', 'ज्ञात', 'पारस्परिक', 'एसी', 'णे', 'उसी', 'चंडी', 'सरकारों', 'तीत', '0000–00', 'हिस', 'rec', 'थियेटर', '१६', 'लाह', '१६', 'डे', 'भि', 'दिन', '१६', 'धूम्रपान', 'उम्मीदवार', 'छू', 'बॉक्स', '१६', 'पहली', 'मोटे', 'bl', 'पेंट', 'बेटा', '१६', 'दिन', 'ख्त', 'इण्डिया', 'chur', '१६', 'आध्यात्म', 'chur', 'किन', 'चार', 'ोत्सव', 'char', 'सूचक', 'बिहारी', 'पड़ोसी', 'नैनी', 'बैंड', 'टीय', 'रथ', 'तालाब', 'अनुमति']\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# exampel of translated sentence\ntext = 'another plant, the aluminium corporation of india, came into existence after the war.'\nprint(translate_sentence(text, model, 64))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:26:25.266692Z","iopub.execute_input":"2024-11-17T08:26:25.267107Z","iopub.status.idle":"2024-11-17T08:26:25.691012Z","shell.execute_reply.started":"2024-11-17T08:26:25.267071Z","shell.execute_reply":"2024-11-17T08:26:25.690044Z"}},"outputs":[{"name":"stdout","text":"['डाला', 'an', '६६७६', 'विजे', 'गढ़वाल', 'हिट', 'टॉप', 'िर', '२००१', 'ताकि', 'आहार', 'िपि', 'वालों', 'पाठक', 'अमृत', 'पारस्परिक', 'माइक्रोस', 'शिश', 'प्रारम्भिक', 'उतार', '्यालय', 'संगठ', 'राज', 'कृषि', '&', 'निर्धारण', 'ऑनलाइन', 'उपभोक्ता', 'उतार', 'उगा', 'चिकित्सक', 'प्रवासी', 'न्यूटन', 'कान', 'मेजर', '))', 'les', 'साइट', 'विश्वविद्यालयों', 'शुर', 'कर्ण', 'गवर्नर', 'हेतु', 'हाँ', 'वाद्य', 'दोनो', 'प्रतिपादन', 'emb', 'जहाँ', 'मार्']\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"optimizer = torch.optim.Adam(model.parameters(), lr=lr)\nloss_fn = nn.CrossEntropyLoss(ignore_index=0) \nscaler = torch.cuda.amp.GradScaler() \nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\nlosses = []\n# for inference\nsentences = ['another plant, the aluminium corporation of india, came into existence after the war.', \n             'He is doing very good these days', 'this guy is totally mad', 'what were you saying that day?']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:26:40.143328Z","iopub.execute_input":"2024-11-17T08:26:40.143722Z","iopub.status.idle":"2024-11-17T08:26:40.970754Z","shell.execute_reply.started":"2024-11-17T08:26:40.143686Z","shell.execute_reply":"2024-11-17T08:26:40.969777Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_155/788890195.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler()\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"# taking the test sentences for checking how good the model is trained\ndef infer(sentences, model, max_seq_len):\n    for idx, sentence in enumerate(sentences):\n        print(f'Example {idx+1}:\\n{sentence}\\n{translate_sentence(sentence, model, max_seq_len)}\\n\\n')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:28:24.573466Z","iopub.execute_input":"2024-11-17T08:28:24.574257Z","iopub.status.idle":"2024-11-17T08:28:24.579783Z","shell.execute_reply.started":"2024-11-17T08:28:24.574215Z","shell.execute_reply":"2024-11-17T08:28:24.578780Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"infer(sentences, model, max_seq_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:28:33.375012Z","iopub.execute_input":"2024-11-17T08:28:33.376208Z","iopub.status.idle":"2024-11-17T08:28:35.012105Z","shell.execute_reply.started":"2024-11-17T08:28:33.376159Z","shell.execute_reply":"2024-11-17T08:28:35.011144Z"}},"outputs":[{"name":"stdout","text":"Example 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['डाला', 'an', '६६७६', 'विजे', 'गढ़वाल', 'हिट', 'टॉप', 'िर', '२००१', 'ताकि', 'आहार', 'िपि', 'वालों', 'पाठक', 'अमृत', 'पारस्परिक', 'माइक्रोस', 'शिश', 'प्रारम्भिक', 'उतार', '्यालय', 'संगठ', 'राज', 'कृषि', '&', 'निर्धारण', 'ऑनलाइन', 'उपभोक्ता', 'उतार', 'उगा', 'चिकित्सक', 'प्रवासी', 'न्यूटन', 'कान', 'मेजर', '))', 'les', 'साइट', 'विश्वविद्यालयों', 'शुर', 'कर्ण', 'गवर्नर', 'हेतु', 'हाँ', 'वाद्य', 'दोनो', 'प्रतिपादन', 'emb', 'जहाँ', 'मार्']\n\n\nExample 2:\nHe is doing very good these days\n['डाला', 'an', '६६७६', 'इंट', 'फ़िल्म', 'लभ', 'सामूहिक', 'रिलीज़', 'right', 'जुल', 'प्रति', 'परिवार', 'ंकार', 'भौ', 'या', 'जान', 'मार्शल', 'गवर्नमेंट', 'सहायक', 'श्रे', 'समुचित', 'ग्लो', 'सक्षम', 'लाने', 'गाँ', 'तस्वी', 'बनाए', 'ंडित', 'सश', 'पश्चिमी', 'डब्ल्यू', 'पहच', 'ूरत', 'युक्त', 'ऊँचे', 'अभिया', 'घर', 'लेने', 'ames', 'विश्वविद्यालयों', 'शुर', 'बोध', 'arn', 'वालों', 'वाशिंगटन', 'आईटी', 'हाइड्रोजन', 'झ', 'करेगा', 'मु']\n\n\nExample 3:\nthis guy is totally mad\n['डाला', 'न्ता', 'ुर', 'उद्योगों', 'आर्क', 'रेटर', 'िति', 'प्रश', 'जनक', 'आया', 'एजेंस', 'केश', 'istricts', 'ार्ट', 'या', 'जान', 'ड्डी', 'native', 'x', 'तेलुग', 'मना', 'पस', 'धरती', 'वजन', 'नियंत्रण', 'तस्वी', 'बनाए', 'विभक्त', 'दिख', 'चौ', 'रण', 'चौथी', 'रास्त', 'रिक्ष', 'िन्न', 'दृ', 'सम्बन्धित', 'बीसी', 'प्रवासी', 'emb', 'जहाँ', 'संद', 'पुणे', 'आइस', 'आंशिक', 'न्टी', 'इज़', 'गेंद', 'घटनाओं', 'िमि']\n\n\nExample 4:\nwhat were you saying that day?\n['डाला', 'न्ता', 'ुर', 'उद्योगों', 'आर्क', 'बॉक्स', 'आत्महत्या', 'देखें', 'आधिकारिक', 'खुश', 'ख', 'वाइ', 'संस्थाप', 'डे', 'चार', 'खतरा', 'to', 'भौ', 'श्ल', 'air', 'कब्जा', 'तीसरी', 'न्दन', 'रह', 'ियार', 'अनुरूप', 'ैम', 'दें', 'ran', '्मण', 'केंद', 'युक्ति', 'संघर्ष', '!!', 'ula', 'अके', 'कथ', 'ला', 'शाह', 'ुद्र', 'उनमें', 'बाघ', 'ज़ी', 'cont', 'नेहरू', 'मछल', 'अकेले', 'ियम', 'साउंड', 'bl']\n\n\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"# training\nfor epoch in range(num_epochs):\n    model.train()\n    losses.append(train(train_loader, model, optimizer, scaler, scheduler, loss_fn, epoch))\n    \n    # save checkpoint\n    checkpoint = {\n        'state_dict': model.state_dict(),\n        'optimizer':optimizer.state_dict()\n    }\n    save_checkpoint(checkpoint)\n    \n    # check accuracy  on test set\n    infer(sentences, model, max_seq_len)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-17T08:28:54.996755Z","iopub.execute_input":"2024-11-17T08:28:54.997594Z","iopub.status.idle":"2024-11-17T08:48:02.296401Z","shell.execute_reply.started":"2024-11-17T08:28:54.997549Z","shell.execute_reply":"2024-11-17T08:48:02.295400Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/352 [00:00<?, ?it/s]/tmp/ipykernel_155/4043967710.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(): # for gradient underflowing and overflowing and it makes training faster by converting all floats to float16\n100%|██████████| 352/352 [00:56<00:00,  6.24it/s, epoch=0, loss=5.99]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'व्यक्ति', 'के', 'कारण', ',', '0000', 'में', ',', 'एक', 'दूसरे', 'की', 'गई', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['उसने', 'कहा', ',', '\"', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'है', 'कि', 'यह', 'है', 'कि', '']\n\n\nExample 4:\nwhat were you saying that day?\n['क्या', 'आप', 'इस', 'पर', 'आप', 'क्या', 'है', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.26it/s, epoch=1, loss=4.71]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'भारत', 'के', 'बारे', 'में', ',', 'भारत', 'के', 'बाद', 'भारत', 'में', ',', 'भारत', 'के', 'बारे', 'में', ',', 'भारत', 'का', 'एक', 'और', 'है', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['ये', 'सब', 'कुछ', 'भी', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'एक', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['क्या', 'तुम', 'ने', 'तुम्', 'ह', 'ें', 'क्या', 'है', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.26it/s, epoch=2, loss=4.57]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'बार', ',', 'भारत', 'के', 'बाद', 'भारत', 'में', ',', 'भारत', 'के', 'बाद', ',', 'भारत', 'के', 'बाद', ',', 'भारत', 'में', 'स्थित', 'है', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'इन', 'बहुत', 'बहुत', 'बहुत', 'अच्छा', 'है', '']\n\n\nExample 3:\nthis guy is totally mad\n['इस', 'प्रकार', 'इस', 'प्रकार', 'का', 'है', '।', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम', 'उस', 'दिन', 'झु', 'ठ', 'ला', 'ओ', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:55<00:00,  6.29it/s, epoch=3, loss=3.55]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'बार', ',', 'भारत', 'के', 'बाद', 'भारत', 'के', 'बाद', 'भारत', 'में', 'स्थित', 'है', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'इन', 'बहुत', 'बहुत', 'अच्छा', 'है', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'ब', 'क्', 'से', 'है', '।', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'ह', 'ें', 'क्या', 'माल', 'ूम', 'कि', 'दिन', 'क्या', 'माल', 'ूम', 'हो', 'गए', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.27it/s, epoch=4, loss=3.48]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'ही', ',', 'भारत', 'के', 'बाद', 'भारत', 'में', 'स्थित', 'एक', 'दम', 'ियां', 'है', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'इन', 'दिनों', 'से', 'बहुत', 'अच्छा', 'है', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'जान', 'ता', 'है', 'कि', 'यह', 'संभव', 'है', '।', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम', 'को', 'क्या', 'माल', 'ूम', 'हाव', 'िया', 'क्या', 'हो', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.27it/s, epoch=5, loss=2.7] \n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'अन्य', 'ोन', '्य', 'भारत', 'के', 'बाद', ',', 'भारत', 'के', 'पश्चात्', 'के', 'पश्चात्', 'दूसरी', 'ओर', 'रु', '.', '']\n\n\nExample 2:\nHe is doing very good these days\n['इन', 'दिनों', 'बहुत', 'अच्छे', 'बच्चे', 'हैं', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'ब', 'राब', 'री', 'वेबसाइट', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'हारी', 'फ़', 'ैस', 'ले', 'का', 'दिन', 'है', 'कि', 'तुम', 'को', 'क्या', 'करते', 'रहे', 'थे', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.27it/s, epoch=6, loss=2.45]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', ',', 'भारत', 'के', 'बाद', ',', 'भारत', 'के', 'बाद', ',', 'भारत', 'में', 'से', 'एक', 'बहुत', 'ही', 'है', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'इन', 'दिनों', 'के', 'दिन', 'में', 'बहुत', 'ही', 'अच्छा', 'है', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'जान', 'ती', 'है', 'कि', 'यह', 'पुराना', 'भी', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'ह', 'ें', 'क्या', 'हो', 'गए', 'थे', 'दिन', 'कित', 'ने', '-', 'एक', 'क्या', 'थी', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.28it/s, epoch=7, loss=2.09]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'अन्य', 'पाद', 'प', 'के', 'बाद', 'भारत', 'के', 'उपरांत', 'भारत', 'में', 'स्थित', 'रहता', 'है', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'तो', 'बहुत', 'अच्छा', 'ही', 'है', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'सा', 'वधान', 'वि', 'राम', 'से', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'ह', 'ें', 'क्या', 'माल', 'ूम', 'कि', 'दिन', 'क्या', 'है', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.27it/s, epoch=8, loss=1.64]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'बार', ',', 'भारत', 'रत्न', 'पुरस्कार', 'प्रदान', 'करने', 'के', 'बाद', 'से', 'बनी', 'हुई', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['ये', 'दोनों', 'बहुत', 'अच्छा', 'अ', 'जी', 'ब', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['इस', 'नस्ल', 'की', 'ता', 'ज़ा', 'अलग', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['दिन', 'को', 'तु', 'झे', 'क्या', 'हो', 'गया', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.26it/s, epoch=9, loss=1.37] \n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'अन्य', 'श्रेणियों', 'के', 'उपरांत', 'भारत', 'के', 'उपरांत', 'उन्होंने', 'श्रम', 'विभाजन', 'के', 'पीछे', 'हट', 'ें', '']\n\n\nExample 2:\nHe is doing very good these days\n['ये', 'ब', 'ङ', 'ा', 'बहुत', 'अच्छा', 'काम', 'कर', 'रहा', 'है', '']\n\n\nExample 3:\nthis guy is totally mad\n['ये', 'आइ', 'वॉ', 'च', 'ट्ट', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'ह', 'ें', 'क्या', 'दिया', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.27it/s, epoch=10, loss=0.923]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', ',', 'भारत', 'के', 'स्वतंत्रता', 'के', 'आ', 'रे', ',', 'भारत', 'में', ',', 'युद्ध', 'में', ',', 'युद्ध', 'था', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['ये', 'दोनों', 'सद', 'ते', 'हैं', 'तो', 'इन', 'दिनों', 'में', 'बहुत', 'अच्छा', 'रहता', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'चलाया', 'जा', 'रहा', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['उस', 'दिन', 'तुम', 'को', 'क्या', 'पता', 'हो', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.27it/s, epoch=11, loss=0.725]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'और', 'बे', 'ज', 'िम', '्म', 'न', 'के', 'आ', 'ब', 'िर', 'का', 'भारत', 'में', 'हुआ', 'था', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['ये', 'उन', 'दिनों', 'बहुत', 'अच्छा', 'रहता', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'प्रकृति', 'एक', 'दम', 'निरा', 'श', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'हारी', 'दिन', 'पहले', 'से', 'दिन', 'क्या', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.28it/s, epoch=12, loss=0.652]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'अन्य', 'ोन', 'िश', 'मन', 'स्य', 'का', 'दूसरा', 'दौरा', 'में', 'प्री', 'तन', 'संगीत', 'के', 'एक', 'दम', 'युद्ध', 'था', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'तो', 'बहुत', 'अच्छा', 'दिन', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'प्रकृति', 'जलवायु', 'यह', 'वि', 'निर्माण', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'हार', 'े', 'दिन', 'बहुत', 'दिन', 'है', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:55<00:00,  6.30it/s, epoch=13, loss=0.59] \n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'भारत', 'के', 'दूर', 'स्थ', 'साम', 'ंत', 'ों', 'में', ',', 'भारत', 'की', 'तरह', 'उ', 'बाल', '.', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'तो', 'बहुत', 'अच्छा', 'दिन', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'केवल', 'एक', 'दम', 'निरा', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'ह', 'ें', 'क्या', 'हो', 'गया', 'है', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.28it/s, epoch=14, loss=0.347]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', ',', 'भारत', 'निगम', 'में', 'उत्तरा', 'खंड', 'ित', 'होने', 'पर', 'स्थित', 'है', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'तो', 'बस', 'एक', 'बहुत', 'अच्छा', 'रहता', 'है', ',', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'केवल', 'बहु', 'विध', 'क्षमता', 'है', '।', '']\n\n\nExample 4:\nwhat were you saying that day?\n['दिन', 'और', 'तु', 'झे', 'क्या', 'है', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:55<00:00,  6.29it/s, epoch=15, loss=0.416]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'और', 'इं', 'टी', 'एम', 'में', 'मधु', 'कर', 'के', 'पीछे', '-', 'कार्य', 'ख', 'न', ',', 'युद्ध', 'हुआ', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['ये', 'च', 'रा', 'बहुत', 'अच्छा', 'दिन', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'होता', 'है', 'जब', 'विकसित', 'की', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'ह', 'ें', 'क्या', 'हो', 'गया', 'था', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.28it/s, epoch=16, loss=0.409]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'और', 'महा', 'भार', 'तः', 'भारत', 'के', 'पीछे', 'ल', 'ोप', 'कर', 'ने', 'अध्यक्ष', 'ों', 'को', 'युद्ध', 'किया', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'तो', 'बस', 'बहुत', 'अच्छा', 'काम', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'तो', 'केवल', 'बह', 'ू', 'ता', 'है', '।', '']\n\n\nExample 4:\nwhat were you saying that day?\n['उस', 'दिन', 'तुम', 'लोग', 'क्या', 'कित', 'ने', 'लगा', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.28it/s, epoch=17, loss=0.381]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'बार', 'श्रेणी', 'के', 'पीछे', 'विश', '्राम', 'के', 'पीछे', 'होने', 'के', 'पीछे', 'विश', '्राम', ',', 'भारत', 'के', 'पीछे', 'प्रा', 'धिकारी', 'के', 'पीछे', 'निकले', '-', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'तो', 'ये', 'बहुत', 'अच्छा', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'प्रकृति', 'एक', 'दम', 'निरा', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'हारी', 'दिन', 'कह', 'ली', 'गयी', 'कि', 'तु', 'झे', 'क्या', 'फ़', 'री', 'ही', 'हुई', 'थीं', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.29it/s, epoch=18, loss=0.33] \n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', 'और', 'निगम', 'भारत', 'के', 'स्वतंत्रता', 'निगम', 'बाद', 'भारत', 'के', 'संरक्षण', 'में', 'बै', 'ठा', 'की', 'है', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['वह', 'तो', 'बड़ी', 'सफलता', 'बहुत', 'अच्छा', 'रहता', 'है', '।', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'हमारी', 'स', 'ोप', 'रि', 'ढ़', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'ह', 'ें', 'क्या', 'हो', 'गया', 'दिन', '?', '']\n\n\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 352/352 [00:56<00:00,  6.29it/s, epoch=19, loss=0.247]\n","output_type":"stream"},{"name":"stdout","text":"-> Saving CheckPoint\nExample 1:\nanother plant, the aluminium corporation of india, came into existence after the war.\n['एक', ',', 'भारत', 'के', 'स्वतंत्रता', ',', 'भारत', 'के', 'पीछे', 'हट', 'कर', 'ने', 'ही', 'महर्षि', 'दिए', '।', '']\n\n\nExample 2:\nHe is doing very good these days\n['ये', 'च', 'ाली', 'बहुत', 'अच्छी', 'बात', 'रखता', 'है', '']\n\n\nExample 3:\nthis guy is totally mad\n['यह', 'हमारी', 'स्वा', 'भाव', 'ित', 'है', '']\n\n\nExample 4:\nwhat were you saying that day?\n['तुम्', 'हारी', 'दिन', 'बहुत', 'दिन', '?', '']\n\n\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}